# CSAT Text Classification (No-Transformers)

Traditional **TFâ€“IDF + linear models** pipeline to predict **Customer Satisfaction Rating** from **support ticket text**.
The intention is to push classical ML to its practical ceiling without heavy transformer models, keeping compute simple.

## âœ¨ Features
- EDA: class distribution, ticket length distribution, optional crosstabs by channel/priority
- Text prep: combine `Ticket Subject` + `Ticket Description`, safe cleaning
- Features: TFâ€“IDF (word 1â€“3, char 2â€“6), large max features (up to 120k each)
- Models: `LinearSVC`, `LogisticRegression (SAGA)`, `SGDClassifier`
- Class balancing: `class_weight='balanced'` (+ optional simple oversampling)
- Tuning: `RandomizedSearchCV` (StratifiedKFold, scoring = macro-F1), also tunes n-gram ranges
- Evaluation: macro/weighted F1, confusion matrix heatmaps, misclassification explorer
- Artifacts: saves best pipeline to `artifacts/csat_text_pipeline_tuned.joblib`

## ğŸ“ Repository Structure
```
csat-text-classification/
â”œâ”€ CSAT_Text_Enhanced_EDA_Tuning.ipynb   # main notebook
â”œâ”€ requirements.txt
â”œâ”€ environment.yml
â”œâ”€ .gitignore
â””â”€ LICENSE
```

## ğŸ§° Environment
Using **Python 3.12.12**.

### Conda (recommended)
```bash
conda env create -f environment.yml
conda activate csat-312
```

### pip
```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac: source .venv/bin/activate
pip install -r requirements.txt
```

## ğŸš€ Quickstart
1. Launch Jupyter:
   ```bash
   jupyter lab
   ```
2. Open `CSAT_Text_Enhanced_EDA_Tuning.ipynb`
3. Provide path to your CSV when prompted. Expected columns:
   - **`Ticket Description`** (text) â€” optionally **`Ticket Subject`** (auto-combined)
   - **`Customer Satisfaction Rating`** (target). If numeric 1â€“5 â†’ auto-cast to categorical strings.
4. Run all cells. The notebook will:
   - Perform EDA
   - Train baselines and pick the best
   - Run expanded hyperparameter search
   - Save the tuned pipeline in `artifacts/`

## ğŸ“Š Results (from sample runs)
> Results vary by dataset. In reported runs, accuracies ranged **~31â€“55%** with macro-F1 **~0.15â€“0.17** and weighted-F1 **~0.43â€“0.50** due to strong class imbalance and label subjectivity.

If your data is cleaner/more balanced, TFâ€“IDF + linear models can approach **70â€“75%** accuracy with macro-F1 near **0.70**.

## ğŸ§ª Inference with the Saved Pipeline
```python
import joblib, pandas as pd
pipe = joblib.load("artifacts/csat_text_pipeline_tuned.joblib")
texts = ["Subject text + description text here"]
pred = pipe.predict(texts)
print(pred)
```

## ğŸ“Œ Notes
- Avoid committing raw CSVs / PII: keep data under `data/` which is in `.gitignore`.
- If classes are highly imbalanced, set `USE_OVERSAMPLE = True` in the notebook and re-run.

## ğŸ“ˆ Future Work
- Integrate **structured features** (e.g., `Ticket Channel`, `Ticket Priority`, SLA times) via `ColumnTransformer` alongside text.
- If compute permits, move to **transformer-based** models (DistilBERT/BERT). These often add **5â€“10%** macro-F1 but are CPU/GPU intensive.

## ğŸ› ï¸ GitHub: How to publish
```bash
cd csat-text-classification
git init
git add .
git commit -m "Initial commit: CSAT TFâ€“IDF pipeline with EDA & tuning"
git branch -M main
git remote add origin https://github.com/USERNAME/csat-text-classification.git
git push -u origin main
```
Replace `USERNAME` with your GitHub handle.
